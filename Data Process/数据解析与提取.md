# 一、XPath

```python
from lxml import etree
text = """
<div>
    <ul>
        <li class="item-0"><a href="link1.html">first</a></li>
        <li class="item-0"><a href="link2.html">second</a></li>
        <li class="item-inactive"><a href="link3.html">third</a></li>
        <li class="item-2"><a href="link4.html">fourth</a>
    </ul>
</div>
"""
html = etree.HTML(text)
results = etree.tostring(html)  # <class 'bytes'>
print(results.decode('utf-8'))  # bytes 转 str
```

注意到text中最后一个li节点没有闭合，而etree模块可以自动修正HTML文本
(上面的输出结果不仅补全了li节点，还自动添加了body、html节点)

也可以直接读取文本文件进行解析
```python
from lxml import etree
html = etree.parse('./test.html', etree.HTMLParser())
results = etree.tostring(html)
print(results.decode('utf-8'))
```

节点、属性、文本获取：

```python
from lxml import etree
html = etree.parse('./test.html', etree.HTMLParser())
results = html.xpath('//li')  # 获取所有li节点  //*表示获取所有节点
print(results)
```

```python
from lxml import etree
html = etree.parse('./test.html', etree.HTMLParser())
results = html.xpath('//li/a') # 获取li节点的直接子节点a
print(results)
```

```python
from lxml import etree
html = etree.parse('./test.html', etree.HTMLParser())
results = html.xpath('//ul//a') # 获取ul节点的子孙节点a
# 注意:这里若是//ul/a就获取不到,因为ul下没有直接的a子节点,只有li节点
print(results)
```

```python
from lxml import etree
html = etree.parse('./test.html', etree.HTMLParser())
results = html.xpath('//a[@href="link4.html"]/../@class')
# ..获取父节点  @获取节点属性 
# [@属性名=属性值] 用于属性匹配
# //a[@href="link4.html"]/parent::*/@class
print(results)  # ['item-2']
```

```py
from lxml import etree
html = etree.parse('./test.html', etree.HTMLParser())
results = html.xpath('//li/a/text()')
print(results)  # ['first', 'second', 'third', 'fourth']
# 若想获取所有内部节点的文本，用//加text()
```

```python
# 若节点有多个属性值，就不能用上面的[@属性名=属性值]来进行属性匹配
# 使用contains来进行属性多值匹配
from lxml import etree
text = """
<li class="li li-a li-b"><a href="link.html">first</a></li>
"""
html = etree.HTML(text)
result = html.xpath('//li[contains(@class, "li-a")]/a/text()')
print(result)
```

```python
# 多属性匹配
from lxml import etree
text = """
<li class="li li-a" name="Ohana"><a href="link.html">first</a></li>
"""
html = etree.HTML(text)
result = html.xpath('//li[contains(@class, "li-a") and @name="Ohana"]/a/text()')
print(result)
```

```python
# 按序选择
from lxml import etree
text = """
<div>
    <ul>
        <li class="item-0"><a href="link1.html">first</a></li>
        <li class="item-0"><a href="link2.html">second</a></li>
        <li class="item-inactive"><a href="link3.html">third</a></li>
        <li class="item-2"><a href="link4.html">fourth</a>
    </ul>
</div>
"""
html = etree.HTML(text)
result = html.xpath('//li[1]/a/text()')
print(result)
result = html.xpath('//li[last()]/a/text()')
print(result)
result = html.xpath('//li[position()<3]/a/text()')
print(result)
result = html.xpath('//li[last()-2]/a/text()')
print(result)
```

> 节点轴选择：
> ancestor::
> attribute::
> child::
> descendant::
> following::
> following-sibling::

# 二、Beautiful Soup

```python
from bs4 import BeautifulSoup
# 初始化BeautifulSoup对象，第二个参数为解释器
soup = BeautifulSoup('<p>Hello bs4</p>', 'lxml')
print(soup.p.string) # 有多个节点时，这种选择方式只能获取第一个匹配的节点
print(type(soup.p))  # <class 'bs4.element.Tag'>
```

```python
from bs4 import BeautifulSoup
text = """
<p name="salute" class="One">Hello bs4</p>
<p class="two">Hello Again</p>
"""
soup = BeautifulSoup(text, 'lxml')
# 对于class属性,由于一个节点可能包括多个class,因此返回的是列表 ['One']
print(soup.p.attrs['class'])
# print(soup.p['name']) 简便的写法
```

对于一个bs4.element.Tag类型的对象同样可以继续调用节点进行下一步的选择

```python
from bs4 import BeautifulSoup
text = """
<div>
    <ul>
        <li>flag</li>
    </ul>
</div>
"""
soup = BeautifulSoup(text, 'lxml')
print(soup.div.ul.li.string)
```

```python
from bs4 import BeautifulSoup
text = """
<p class="story">
   Once upon a time there were two little sisters; and their names were
   <a href="http://aaa.com/elsie" class="sister"  id="1">
       <span>Elsie</span>
   </a>
   and
   <a  href="http://aaa.com/lacie" class="sister"  id="2">
       <span>Lacie</span>
   </a>
</p>
"""
soup = BeautifulSoup(text, 'lxml')
print(soup.p.contents)
```

> ['\n   Once upon a time there were two little sisters; and their names were\n   ', 
> \<a class="sister" href="http://aaa.com/elsie" id="1">
> \<span>Elsie</span>
> </a>, '\n   and\n   ', \<a class="sister" href="http://aaa.com/lacie" id="2">
> \<span>Lacie</span>
> </a>, '\n']

发现列表中每个元素都是p节点的直接子节点（包括文本节点）

```python
from bs4 import BeautifulSoup
text = """"""
soup = BeautifulSoup(text, 'lxml')
for i, child in enumerate(soup.p.children):
    print(i, child)
# 也可以用children属性
```

同理，还有其他属性
descendants、parent、parents、next_sibling、previous_sibling、
next_siblings、previous_siblings

前面的节点选择都是基于属性，下面介绍方法选择器

```python
from bs4 import BeautifulSoup
text = """
<div>
    <ul class="fruit">
        <li>Apple</li>
        <li>Banana</li>
    </ul>
    <ul class="meat">
        <li>Beef</li>
        <li>Lamb</li>
    </ul>
<div>
"""
soup = BeautifulSoup(text, 'lxml')
for ul in soup.find_all(name='ul'):
    print('***' + ul['class'][0] + '***')
    for li in ul.find_all(name='li'):
        print(li.string)
```

```python
from bs4 import BeautifulSoup
# 除了使用节点名查询，也可以传入属性进行查询
text = """
<div>
    <ul class="fruit">
        <li>Apple</li>
        <li>Banana</li>
    </ul>
    <ul class="meat">
        <li>Beef</li>
        <li>Lamb</li>
    </ul>
<div>
"""
soup = BeautifulSoup(text, 'lxml')
for ul in soup.find_all(attrs={'class': 'meat'}):
    for li in ul.children:
        print(li.string)
```

对于一些常用的属性，如id、class，可以不用attrs传递
直接传入            id='xxx'       或     class_='xxx'

```python
# text参数可以用来匹配节点的文本，可以传入字符串或正则表达式对象
from bs4 import BeautifulSoup
import re
html = """
<div class="panel">
    <a>Hello, this a link</a>
    <a>I am a link too</a>
</div>
"""
soup = BeautifulSoup(html, 'lxml')
print(soup.find_all(text=re.compile('link')))
# ['Hello, this a link', 'I am a link too']
```

find方法也可以查询符合条件的元素，不过find返回的是第一个匹配的元素

同理还有其他方法
find_parent、find_parents、
find_next_siblings、find_next_sibling
find_previous_siblings、find_previous_sibling
find_all_next、find_next
find_all_previous、find_previous

soup.select(CSS选择器)