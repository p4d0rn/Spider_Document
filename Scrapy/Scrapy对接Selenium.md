# Scrapy to Selenium

å¯¹æ¥åŸç†ï¼š

å½“Downloader Middlewareçš„process_requestsæ–¹æ³•è¿”å›Responseå¯¹è±¡æ—¶ï¼Œæ­¤æ—¶åè½¬æ–¹å‘ï¼Œè°ƒç”¨ä¹‹å‰ä¸­é—´ä»¶çš„process_responseæ–¹æ³•ï¼Œè°ƒç”¨å®Œåå°†Responseå¯¹è±¡ä¼ ç»™Spiderå¤„ç†ã€‚

æ‰€ä»¥æˆ‘ä»¬çš„é˜»æˆªç‚¹åœ¨Downloader Middlewareçš„process_requestsæ–¹æ³•ï¼Œåœ¨è¿™ä¸ªæ–¹æ³•ä¸­è·å–Requestå¯¹è±¡çš„URLï¼Œç„¶åä½¿ç”¨seleniumå®ŒæˆURLè¯·æ±‚ï¼Œè¿”å›ç»è¿‡JavaScriptæ¸²æŸ“åçš„HTMLé¡µé¢ï¼Œå³HtmlResponseå¯¹è±¡ã€‚

# å®æˆ˜

ğŸ“ŒTargetï¼šhttps://spa5.scrape.center/

:wrench:Toolï¼šSelenium

ç‚¹è¿›å›¾ä¹¦è¯¦æƒ…é¡µï¼ŒæŠ“åŒ…å¯çŸ¥é¡µé¢æ˜¯é€šè¿‡ajaxåŠ¨æ€æ¸²æŸ“å‡ºæ¥çš„

é¦–å…ˆå®šä¹‰Itemç±»

```python
import scrapy
from scrapy import Field


class BookItem(scrapy.Item):
    name = Field()
    authors = Field()
    score = Field()
    price = Field()
    tags = Field()
```

ç¼–å†™ä¸­é—´ä»¶
```python
import time
from selenium import webdriver
from selenium.webdriver import ChromeOptions
from scrapy.http import HtmlResponse


class SeleniumDownloaderMiddleware:

    def process_request(self, request, spider):
        option = ChromeOptions()
        option.add_argument('--headless') # è®¾ç½®æ— å¤´æ¨¡å¼
        browser = webdriver.Chrome(options=option)
        browser.get(request.url)
        time.sleep(1)
        source = browser.page_source
        browser.close()
        return HtmlResponse(url=request.url,
                            body=source,
                            request=request,
                            encoding='utf-8',
                            status=200)
```

settings.pyä¸­æ³¨å†Œä¸­é—´ä»¶

```python
# settings.py
DOWNLOADER_MIDDLEWARES = {
   'book.middlewares.SeleniumDownloaderMiddleware': 543,
}
ROBOTSTXT_OBEY = False
```

ç¼–å†™Spider

```python
import scrapy
from scrapy import Request
from book.items import BookItem


class Spa5Spider(scrapy.Spider):
    name = 'spa5'
    allowed_domains = ['spa5.scrape.center']
    start_url = 'http://spa5.scrape.center'
    max_page = 1

    def start_requests(self):
        for i in range(1, self.max_page + 1):
            url = self.start_url + f'/page/{i}'
            yield Request(url=url, callback=self.parse_index)

    def parse_index(self, response):
        for url in response.css('.top a::attr(href)').extract():
            detail_url = self.start_url + url
            yield Request(url=detail_url, callback=self.parse_detail, priority=2)

    def parse_detail(self, response):
        book = BookItem()
        book['tags'] = []
        book['name'] = response.css('a h2::text').extract_first()
        book['authors'] = response.css('.authors::text').re_first('ä½œè€…ï¼š(.*)').strip().split(' ')
        book['score'] = response.css('.score::text').extract_first().strip()
        book['price'] = response.css('.price span::text').extract_first()
        for tag in response.css('.tags span::text').extract():
            book['tags'].append(tag.strip())
        yield book
```

![image-20221031130302561](../images/image-20221031130302561.png)

ä¸Šé¢çš„SeleniumDownloaderMiddlewareè¿‡äºç²—ç³™ï¼Œå¦‚æ²¡æœ‰è®¾ç½®å¹¶å‘æ•°ï¼ŒåŒä¸€æ—¶åˆ»åªæœ‰ä¸€ä¸ªé¡µé¢å¯ä»¥è¢«æ¸²æŸ“ï¼Œå˜æˆé˜»å¡å¼çˆ¬å–ï¼Œçˆ¬å–æ•ˆç‡å¤§å¤§é™ä½

å´”ä½¬å†™äº†ä¸ªåŒ… `pip install gerapy-selenium`

```python
# settings.py
DOWNLOADER_MIDDLEWARES = {
   'gerapy_selenium.downloadermiddlewares.SeleniumMiddleware': 543,
}
CONCURRENT_REQUEST = 6
```

```python
# spa5.py
def start_requests(self):
    for i in range(1, self.max_page + 1):
        url = self.start_url + f'/page/{i}'
        yield SeleniumRequest(url=url, callback=self.parse_index, wait_for='.top a')

        def parse_index(self, response):
            for url in response.css('.top a::attr(href)').extract():
                detail_url = self.start_url + url
                yield SeleniumRequest(url=detail_url, callback=self.parse_detail, priority=2)
```

